{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install pylibjpeg pylibjpeg-libjpeg pydicom\n! pip install -U python-gdcm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-04T10:06:22.515568Z","iopub.execute_input":"2022-09-04T10:06:22.516958Z","iopub.status.idle":"2022-09-04T10:06:48.062306Z","shell.execute_reply.started":"2022-09-04T10:06:22.516850Z","shell.execute_reply":"2022-09-04T10:06:48.060991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;\n            background-color: #A020F0;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 4px;color:white;\"><b>1 Libraries</b></p>\n</div>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport seaborn as sns\nimport cv2\nimport os\nfrom os import listdir\nimport re\nimport gc\nimport gdcm\nimport pydicom\nfrom pydicom import dcmread\nimport pylibjpeg\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport scipy.ndimage\nfrom tqdm import tqdm\nfrom pprint import pprint\nfrom time import time\nimport itertools\nfrom skimage import measure \nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\nimport nibabel as nib\nfrom glob import glob\nimport warnings\nimport dask.array as da\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import losses, callbacks\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom PIL import Image as im\nfrom keras.models import load_model\nfrom random import shuffle\nimport random\n%matplotlib inline\nsns.set(style='darkgrid', font_scale=1.6)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:06:48.064910Z","iopub.execute_input":"2022-09-04T10:06:48.065341Z","iopub.status.idle":"2022-09-04T10:06:56.343635Z","shell.execute_reply.started":"2022-09-04T10:06:48.065291Z","shell.execute_reply":"2022-09-04T10:06:56.342706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;\n            background-color: #A020F0;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 4px;color:white;\"><b>2 Activating Devices</b></p>\n</div>","metadata":{}},{"cell_type":"code","source":"DEVICE = \"GPU\"\nif DEVICE == \"TPU\":\n    print(\"connecting to TPU...\")\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        print(\"Could not connect to TPU\")\n        tpu = None\n\n    if tpu:\n        try:\n            print(\"initializing  TPU ...\")\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n            print(\"TPU initialized\")\n        except _:\n            print(\"failed to initialize TPU\")\n    else:\n        DEVICE = \"GPU\"\n\nif DEVICE != \"TPU\":\n    print(\"Using default strategy for CPU and single GPU\")\n    strategy = tf.distribute.get_strategy()\n\nif DEVICE == \"GPU\":\n    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n    \n\nAUTO     = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:06:56.344965Z","iopub.execute_input":"2022-09-04T10:06:56.345843Z","iopub.status.idle":"2022-09-04T10:06:56.448779Z","shell.execute_reply.started":"2022-09-04T10:06:56.345797Z","shell.execute_reply":"2022-09-04T10:06:56.447531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;\n            background-color: #A020F0;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 4px;color:white;\"><b>3 Data</b></p>\n</div>\n","metadata":{}},{"cell_type":"code","source":"#For Segmentation data\ndef load_NIfTI(path):\n    mask = nib.load(path)\n    \n    # Convert to numpy array\n    seg = mask.get_fdata()\n    \n    # Align orientation with images\n    seg = seg[:, ::-1, ::-1].transpose(2, 1, 0)\n    \n    return seg","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:06:56.451739Z","iopub.execute_input":"2022-09-04T10:06:56.452896Z","iopub.status.idle":"2022-09-04T10:06:56.458543Z","shell.execute_reply.started":"2022-09-04T10:06:56.452858Z","shell.execute_reply":"2022-09-04T10:06:56.457577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Getting patient with mask\nseg_paths = glob(f\"../input/rsna-2022-cervical-spine-fracture-detection/segmentations/*\")\ntraining_patient=[]\nfor path in seg_paths:\n    training_patient.append((path.rsplit(\"/\",1)[-1])[:-4])#Patient with mask present","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:06:56.459968Z","iopub.execute_input":"2022-09-04T10:06:56.460354Z","iopub.status.idle":"2022-09-04T10:06:56.474595Z","shell.execute_reply.started":"2022-09-04T10:06:56.460317Z","shell.execute_reply":"2022-09-04T10:06:56.473681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Example segment image\npath_mask=f\"../input/rsna-2022-cervical-spine-fracture-detection/segmentations/{training_patient[0]}.nii\"\npatient_mask=load_NIfTI(path_mask)\n\npatient_mask.shape","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:06:56.476106Z","iopub.execute_input":"2022-09-04T10:06:56.477191Z","iopub.status.idle":"2022-09-04T10:06:57.238365Z","shell.execute_reply.started":"2022-09-04T10:06:56.477155Z","shell.execute_reply":"2022-09-04T10:06:57.237423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot segment images\nfig, axes = plt.subplots(nrows=3, ncols=6, figsize=(24,12))\nfig.suptitle(f'ID: {training_patient[0]}', weight=\"bold\", size=20)\n\nstart=110\nfor i in range(start,start+18):\n    mask = patient_mask[i]\n    slice_no = i\n\n    # Plot the image\n    x = (i-110) // 6\n    y = (i-110) % 6\n\n    axes[x, y].imshow(mask, cmap='bone')\n    axes[x, y].set_title(f\"Slice: {slice_no}\", fontsize=14, weight='bold')\n    axes[x, y].axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:06:57.239742Z","iopub.execute_input":"2022-09-04T10:06:57.240109Z","iopub.status.idle":"2022-09-04T10:06:59.806710Z","shell.execute_reply.started":"2022-09-04T10:06:57.240074Z","shell.execute_reply":"2022-09-04T10:06:59.805611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loading Scans\ndef atoi(text):\n    return int(text) if text.isdigit() else text\ndef natural_keys(text):\n    return [atoi(c) for c in re.split(r'(\\d+)', text)]\n\n# Load the scans in given folder path\ndef load_scan(path):\n    \n    dcm_paths = glob(f\"{path}/*\")\n    dcm_paths.sort(key=natural_keys)\n    \n    patient_scan = [pydicom.dcmread(paths) for paths in dcm_paths]\n    \n    return patient_scan","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:06:59.807963Z","iopub.execute_input":"2022-09-04T10:06:59.808832Z","iopub.status.idle":"2022-09-04T10:06:59.816036Z","shell.execute_reply.started":"2022-09-04T10:06:59.808796Z","shell.execute_reply":"2022-09-04T10:06:59.814754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Example Scan\npath_scan=f\"../input/rsna-2022-cervical-spine-fracture-detection/train_images/{training_patient[0]}\"\nimage=load_scan(path_scan)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:06:59.817758Z","iopub.execute_input":"2022-09-04T10:06:59.818231Z","iopub.status.idle":"2022-09-04T10:07:01.906470Z","shell.execute_reply.started":"2022-09-04T10:06:59.818195Z","shell.execute_reply":"2022-09-04T10:07:01.905381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot images\nfig, axes = plt.subplots(nrows=3, ncols=6, figsize=(24,12))\nfig.suptitle(f'ID: {training_patient[0]}', weight=\"bold\", size=20)\n\nstart = 110\nfor i in range(start,start+18):\n    img = image[i].pixel_array\n    slice_no = i\n\n    # Plot the image\n    x = (i-start) // 6\n    y = (i-start) % 6\n\n    axes[x, y].imshow(img, cmap=\"bone\")\n    axes[x, y].set_title(f\"Slice: {slice_no}\", fontsize=14, weight='bold')\n    axes[x, y].axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:07:01.912177Z","iopub.execute_input":"2022-09-04T10:07:01.912999Z","iopub.status.idle":"2022-09-04T10:07:04.334454Z","shell.execute_reply.started":"2022-09-04T10:07:01.912960Z","shell.execute_reply":"2022-09-04T10:07:04.333653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;\n            background-color: #A020F0;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 4px;color:white;\"><b>4 Preprocessing</b></p>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;\n            background-color: #A020F0;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 4px;color:white;\"><b>4.1 Loding and Conversion to HU</b></p>\n</div>","metadata":{}},{"cell_type":"code","source":"def get_pixels_hu(slices):\n   \n    image = np.stack([cv2.resize(s.pixel_array,(512,512),interpolation = cv2.INTER_NEAREST) for s in slices])\n    \n    # Convert to int16 (from sometimes int16), \n    # should be possible as values should always be low enough (<32k)\n    image = image.astype(np.int16)\n    image = da.from_array(image) #Using Dask to speed up processing\n    \n    # Set outside-of-scan pixels to 0\n    # The intercept is usually -1024, so air is approximately 0\n    image[image <= -1000] = 0\n    \n    # Convert to Hounsfield units (HU)\n        \n    intercept = da.from_array([slices[slice_number].RescaleIntercept for slice_number in range(len(slices))])\n    slope = da.from_array([slices[slice_number].RescaleSlope for slice_number in range(len(slices))])\n    \n    intercept=intercept.reshape((-1,1,1))\n    slope=slope.reshape((-1,1,1))\n    \n    image= slope * image.astype(\"float64\")\n        \n    image+= intercept\n     \n    return image.astype(\"int16\")","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:07:04.335703Z","iopub.execute_input":"2022-09-04T10:07:04.336777Z","iopub.status.idle":"2022-09-04T10:07:04.347496Z","shell.execute_reply.started":"2022-09-04T10:07:04.336732Z","shell.execute_reply":"2022-09-04T10:07:04.346228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patient_slice=get_pixels_hu(image)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:07:04.349749Z","iopub.execute_input":"2022-09-04T10:07:04.350158Z","iopub.status.idle":"2022-09-04T10:07:04.665351Z","shell.execute_reply.started":"2022-09-04T10:07:04.350125Z","shell.execute_reply":"2022-09-04T10:07:04.664278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Ploting pixel array\nplt.imshow(image[110].pixel_array,cmap='bone')\nplt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:07:04.666904Z","iopub.execute_input":"2022-09-04T10:07:04.667357Z","iopub.status.idle":"2022-09-04T10:07:04.886506Z","shell.execute_reply.started":"2022-09-04T10:07:04.667319Z","shell.execute_reply":"2022-09-04T10:07:04.885530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Ploting pixel array distribution\nplt.hist(image[110].pixel_array.flatten(),color=\"r\",bins=50)\nplt.xlabel(\"Pixel Values\")\nplt.ylabel(\"Fequency\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:07:04.887966Z","iopub.execute_input":"2022-09-04T10:07:04.888998Z","iopub.status.idle":"2022-09-04T10:07:05.191438Z","shell.execute_reply.started":"2022-09-04T10:07:04.888952Z","shell.execute_reply":"2022-09-04T10:07:05.190538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Ploting HU array\nplt.imshow(patient_slice[110],cmap='bone')\nplt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:07:05.193413Z","iopub.execute_input":"2022-09-04T10:07:05.194426Z","iopub.status.idle":"2022-09-04T10:07:05.909601Z","shell.execute_reply.started":"2022-09-04T10:07:05.194386Z","shell.execute_reply":"2022-09-04T10:07:05.908527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Ploting HU distribution\nplt.hist(patient_slice[110].flatten().compute(),color=\"r\",bins=50)\nplt.xlabel(\"HU Values\")\nplt.ylabel(\"Fequency\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:07:05.911037Z","iopub.execute_input":"2022-09-04T10:07:05.911831Z","iopub.status.idle":"2022-09-04T10:07:06.715592Z","shell.execute_reply.started":"2022-09-04T10:07:05.911791Z","shell.execute_reply":"2022-09-04T10:07:06.714605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;\n            background-color: #A020F0;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 4px;color:white;\"><b>4.2 Normalization</b></p>\n</div>\n\nAs HU values range from **150** to **2050**. So we will use this values for normalization.","metadata":{}},{"cell_type":"code","source":"MIN_BOUND = 150.0\nMAX_BOUND = 2050.0\n    \ndef normalize(image):\n    image = (image - MIN_BOUND)*255.0 / (MAX_BOUND - MIN_BOUND)\n    image[image>255] = 255.\n    image[image<0] = 255.\n    return image","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:07:06.717169Z","iopub.execute_input":"2022-09-04T10:07:06.719218Z","iopub.status.idle":"2022-09-04T10:07:06.725972Z","shell.execute_reply.started":"2022-09-04T10:07:06.719173Z","shell.execute_reply":"2022-09-04T10:07:06.725003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image=normalize(patient_slice)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:07:06.727478Z","iopub.execute_input":"2022-09-04T10:07:06.728080Z","iopub.status.idle":"2022-09-04T10:07:06.746366Z","shell.execute_reply.started":"2022-09-04T10:07:06.728042Z","shell.execute_reply":"2022-09-04T10:07:06.745432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(image[110],cmap=\"bone\")\nplt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:07:06.749358Z","iopub.execute_input":"2022-09-04T10:07:06.749845Z","iopub.status.idle":"2022-09-04T10:07:08.033566Z","shell.execute_reply.started":"2022-09-04T10:07:06.749812Z","shell.execute_reply":"2022-09-04T10:07:08.032597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Delete all unused objects to free up memory\ndel patient_slice\ndel image\ndel fig\ndel axes\ndel path_scan\ndel path_mask\ndel patient_mask\ndel seg_paths\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:07:08.035068Z","iopub.execute_input":"2022-09-04T10:07:08.035420Z","iopub.status.idle":"2022-09-04T10:07:08.288997Z","shell.execute_reply.started":"2022-09-04T10:07:08.035384Z","shell.execute_reply":"2022-09-04T10:07:08.287811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;\n            background-color: #A020F0;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 4px;color:white;\"><b>5 Model</b></p>\n</div>","metadata":{}},{"cell_type":"code","source":"#Segreggate the preprocessed image in these folders based on Segmentation data in Training Folder.\ndef segregate_Train(start,X_train_patient):\n    \n    train_ds_x=[]\n    train_ds_y=[]\n    for i in range(start,start+5):\n        patient_ID=X_train_patient[i]\n        \n        patient_seg=load_NIfTI(f\"../input/rsna-2022-cervical-spine-fracture-detection/segmentations/{patient_ID}.nii\")\n        \n        patient_scan=load_scan(f\"../input/rsna-2022-cervical-spine-fracture-detection/train_images/{patient_ID}\")\n        patient_hu=get_pixels_hu(patient_scan)\n        patient_hu_normalised=normalize(patient_hu)\n        \n        for j in tqdm(range(0,len(patient_seg))):\n            classes=np.unique(patient_seg[j])\n        \n            temp_lables=np.zeros(9)\n            for k in classes:\n                if int(k)!=0:\n                    if int(k)<8:\n                        temp_lables[int(k)]=1\n                    else:\n                        temp_lables[8]=1\n                else:\n                    temp_lables[0]=1\n            \n            train_ds_x.append(patient_hu_normalised[j].astype(np.uint8))\n            train_ds_y.append(temp_lables.astype(np.uint8))\n        \n    return train_ds_x,train_ds_y","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:07:08.293007Z","iopub.execute_input":"2022-09-04T10:07:08.293372Z","iopub.status.idle":"2022-09-04T10:07:08.334172Z","shell.execute_reply.started":"2022-09-04T10:07:08.293343Z","shell.execute_reply":"2022-09-04T10:07:08.332371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Segreggate the preprocessed image in these folders based on Segmentation data in Training Folder.\ndef segregate_Val(start,X_Val_patient):\n    \n    val_ds_x=[]\n    val_ds_y=[]\n    for i in range(start,start+2):\n        patient_ID=X_Val_patient[i]\n        \n        patient_seg=load_NIfTI(f\"../input/rsna-2022-cervical-spine-fracture-detection/segmentations/{patient_ID}.nii\")\n        \n        patient_scan=load_scan(f\"../input/rsna-2022-cervical-spine-fracture-detection/train_images/{patient_ID}\")\n        patient_hu=get_pixels_hu(patient_scan)\n        patient_hu_normalised=normalize(patient_hu)\n        \n        for j in tqdm(range(0,len(patient_seg))):\n            classes=np.unique(patient_seg[j])\n        \n            temp_lables=np.zeros(9)\n            for k in classes:\n                if int(k)!=0:\n                    if int(k)<8:\n                        temp_lables[int(k)]=1\n                    else:\n                        temp_lables[8]=1\n                else:\n                    temp_lables[0]=1\n            \n            val_ds_x.append(patient_hu_normalised[j].astype(np.uint8))\n            val_ds_y.append(temp_lables.astype(np.uint8))\n        \n    return val_ds_x,val_ds_y","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:07:08.337829Z","iopub.execute_input":"2022-09-04T10:07:08.338455Z","iopub.status.idle":"2022-09-04T10:07:08.361270Z","shell.execute_reply.started":"2022-09-04T10:07:08.338412Z","shell.execute_reply":"2022-09-04T10:07:08.360228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Defining the model\ndef model_CNN():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (512,512,1)),\n        tf.keras.layers.Conv2D(filters = 8, kernel_size = (3,3), activation ='relu'),\n        tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n        tf.keras.layers.Dropout(0.30),\n        tf.keras.layers.Conv2D(filters = 64, kernel_size = (7,7),padding = 'Same', activation ='relu'),\n        tf.keras.layers.Conv2D(filters = 8, kernel_size = (5,5), activation ='relu'),\n        tf.keras.layers.MaxPool2D(pool_size=(4, 4)),\n        tf.keras.layers.Dropout(0.30),\n        tf.keras.layers.Conv2D(filters = 8, kernel_size = (7,7),padding = 'Same', activation ='relu'),\n        tf.keras.layers.Conv2D(filters = 64, kernel_size = (5,5), activation ='relu'),\n        tf.keras.layers.MaxPool2D(pool_size=(6, 6)),\n        tf.keras.layers.Dropout(0.30),\n        tf.keras.layers.Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', activation ='relu'),\n        tf.keras.layers.Conv2D(filters = 16, kernel_size = (7,7), activation ='relu'),\n        tf.keras.layers.MaxPool2D(pool_size=(3, 3)),\n        tf.keras.layers.Dropout(0.30),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(12,activation=\"ReLU\"),\n        tf.keras.layers.Dense(9, activation='softmax')\n    ])\n    model.build([None, 512, 512, 1])\n    print(model.summary())\n\n    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n              loss=tf.keras.losses.BinaryCrossentropy(),\n              metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:07:08.363791Z","iopub.execute_input":"2022-09-04T10:07:08.365851Z","iopub.status.idle":"2022-09-04T10:07:08.396420Z","shell.execute_reply.started":"2022-09-04T10:07:08.365807Z","shell.execute_reply":"2022-09-04T10:07:08.395107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_patient, X_Val_patient = train_test_split(training_patient,train_size=70,test_size=17,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:07:08.398930Z","iopub.execute_input":"2022-09-04T10:07:08.399444Z","iopub.status.idle":"2022-09-04T10:07:08.422397Z","shell.execute_reply.started":"2022-09-04T10:07:08.399403Z","shell.execute_reply":"2022-09-04T10:07:08.421369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit(Fold,model):\n    shuffle(X_train_patient)\n    shuffle(X_Val_patient)\n    \n    train_ds_x,train_ds_y=segregate_Train(5*Fold,X_train_patient)\n    val_ds_x,val_ds_y=segregate_Val(2*Fold,X_Val_patient)\n    \n    #Convert into specific format from tensorflow model\n    train_ds_x=da.array(train_ds_x)\n    train_ds_y=da.array(train_ds_y)\n    val_ds_x=da.array(val_ds_x)\n    val_ds_y=da.array(val_ds_y)\n    \n    train_ds_x=np.reshape(train_ds_x,(-1,512,512,1))\n    val_ds_x=np.reshape(val_ds_x,(-1,512,512,1))\n    \n    #Data augmentation\n    datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # dimesion reduction\n        rotation_range=5,  # randomly rotate images in the range 5 degrees\n        zoom_range = 0.1, # Randomly zoom image 10%\n        width_shift_range=0.1,  # randomly shift images horizontally 10%\n        height_shift_range=0.1,  # randomly shift images vertically 10%\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True)  # randomly flip images\n\n    datagen.fit(train_ds_x)\n    data=datagen.flow(train_ds_x,train_ds_y)\n    \n    early_stopping = callbacks.EarlyStopping(\n        min_delta=0.001, # minimium amount of change to count as an improvement\n        patience=5, # how many epochs to wait before stopping\n        restore_best_weights=True,\n    )\n    \n    model.fit(data,epochs=100,shuffle=True,callbacks=[early_stopping],validation_data=(val_ds_x,val_ds_y))\n    \n    if os.path.exists(\"./Classifier.h5\"):\n        os.remove(\"./Classifier.h5\")\n    model.save(\"Classifier.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:07:08.428507Z","iopub.execute_input":"2022-09-04T10:07:08.429060Z","iopub.status.idle":"2022-09-04T10:07:08.449704Z","shell.execute_reply.started":"2022-09-04T10:07:08.429021Z","shell.execute_reply":"2022-09-04T10:07:08.448209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0,15):\n    if os.path.exists(\"./Classifier.h5\"):\n        keras.backend.clear_session()\n        fit(random.randint(0,7),keras.models.load_model(\"./Classifier.h5\"))\n    else:\n        fit(random.randint(0,7),model_CNN())","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:07:08.455244Z","iopub.execute_input":"2022-09-04T10:07:08.458784Z","iopub.status.idle":"2022-09-04T10:10:29.336206Z","shell.execute_reply.started":"2022-09-04T10:07:08.458741Z","shell.execute_reply":"2022-09-04T10:10:29.334715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}